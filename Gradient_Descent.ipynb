{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Root_Insurance_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we implement gradient descent to minimize cost per customer acquired, \n",
    "$$\n",
    "    \\underset {b_i \\geq 0} {\\arg\\,\\min\\,} \\mathcal L(b_1,\\ldots,b_{36}) = \\frac {\\mathbb E[ \\mathrm{Cost} ]}{\\mathbb E[\\# \\mathrm{policies}]}\n",
    "$$\n",
    "with the constraint that the solution acuire at least 400 customers per 10,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we naively minimize cost per customer acquired without any constraint, all the bids will tend to zero. Indeed, if we bid \\\\$0 on every customer, we'll still hold the 5th (last) ranking for every customer, where we would expect to maintain about 2\\% click-thru rate on average. Of the customers that click, some, about 40\\% on average, will end up buying policies and we will have achieved the absolute minimal cost per customer acquired, ending up with about 80 customers per 10,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we find a solution which acquires enough customers, we multiply the cost per customer acquired by a barrier function:\n",
    "$$\n",
    "    \\underset {b_i \\geq 0} {\\arg\\,\\min\\,} \\mathcal L(b_1,\\ldots,b_{36}) = \\frac {\\mathbb E[ \\mathrm{Cost} ]}{\\mathbb E[\\# \\mathrm{policies}]} \\bigg( \\frac 1 {\\mathbb E[ \\mathrm{Policies} ] - 400} + 1 \\bigg).\n",
    "$$\n",
    "\n",
    "This forces the loss function to infinity as the number of expected policies tends to 400, and, since the barrier function tends to one for points far enough away from the barrier, it is comparable to the cost per customer which we wish to estimate.\n",
    "\n",
    "Thus, by optimizing the loss function multiplied by a barrier, we will find an efficient solution within the constrained region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we optimize the loss function by running gradient flow on its logarithm, which is equivalent to minimizing the objective function itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Logistic Regression to get the Probabilities of Different Customers to Buy Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're estimating the probabilities using only customers who click, so that this estimates the true probability of customers to buy a policy, independent of where our ad was ranked.\n",
    "\n",
    "As we observed in the modeling phase, the variables for unknown insurance status and marital status are not statistically significant, so we will fit the model omiting these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame of customers who clicked our ad\n",
    "# we will estimate the probabilities for each customer to buy a policy conditioned on clicking the ad\n",
    "\n",
    "xdf_click = pd.get_dummies(df[\"Currently Insured\"].loc[df.click])[[\"Y\",\"unknown\"]]\n",
    "# rename the column without a space\n",
    "xdf_click.columns = [\"insured\",\"unknown\"]\n",
    "xdf_click[[\"cars2\",\"cars3\"]] = pd.get_dummies(df[\"Number of Vehicles\"].loc[df.click])[[2,3]]\n",
    "xdf_click[[\"drivers2\"]] = pd.get_dummies(df[\"Number of Drivers\"].loc[df.click])[[1]]\n",
    "xdf_click[[\"married\"]] = pd.get_dummies(df[\"Marital Status\"].loc[df.click])[[\"M\"]]\n",
    "xdf_click[[\"policies_sold\"]] = df[[\"policies_sold\"]].loc[df.click].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = LogisticRegression()\n",
    "\n",
    "X = xdf_click[[\"insured\",\"cars2\",\"cars3\",\"drivers2\"]].to_numpy()\n",
    "y = xdf_click[\"policies_sold\"].to_numpy()\n",
    "glm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of categories\n",
    "cat = 36\n",
    "# initialize np array for class probabilities\n",
    "p = np.zeros(cat)\n",
    "# create list to remember the numbers\n",
    "ls = pd.DataFrame(columns=[\"insured\",\"cars\",\"drivers\",\"married\"])\n",
    "idx = 0\n",
    "for i in [\"Y\",\"unknown\",\"N\"]:\n",
    "    for c in [1,2,3]:\n",
    "        for d in [1,2]:\n",
    "            for m in [\"M\",\"S\"]:\n",
    "                x = [[ (i==\"Y\"),(c==2),(c==3),(d==2)]]\n",
    "                # get probability for class idx\n",
    "                p[idx] = glm.predict_proba(x)[0,1]\n",
    "                ls = ls.append({\"insured\":i,\"cars\":c,\"drivers\":d,\"married\":m},ignore_index=True)\n",
    "                idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Coefficients for Click-Thru rate by Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_rates_by_rank = df.groupby(\"rank\").click.mean().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent for Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $\\lambda = 10 \\frac {(\\overline r-1)}{5 - \\overline r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = np.zeros(36)\n",
    "df[\"class\"]=0\n",
    "idx=0\n",
    "r=0\n",
    "for i in [\"Y\",\"unknown\",\"N\"]:\n",
    "    for c in [1,2,3]:\n",
    "        for d in [1,2]:\n",
    "            for m in [\"M\",\"S\"]:\n",
    "                # get the average rank for class idx\n",
    "                r = df[\"rank\"].loc[(df[\"Marital Status\"]==m)&(df[\"Number of Drivers\"]==d)\\\n",
    "                                 &(df[\"Number of Vehicles\"]==c)&(df[\"Currently Insured\"]==i)].mean()\n",
    "                df.loc[(df[\"Marital Status\"]==m)&(df[\"Number of Drivers\"]==d)\\\n",
    "                                 &(df[\"Number of Vehicles\"]==c)&(df[\"Currently Insured\"]==i),\"class\"] = idx\n",
    "                # there is one class (unknown insurance, single, 3 vehicles, 2 drivers); idx = 24\n",
    "                # that has zero representatives, \n",
    "                # for this one we will use the global average bid\n",
    "                # alternatively we could estimate it with logistic regression\n",
    "                # for now we set it to the average rank=3.1841\n",
    "                if np.isnan(r):\n",
    "                    r = df[\"rank\"].mean()\n",
    "                lm[idx] = 10*(r - 1)/(5-r)\n",
    "                idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization parameter\n",
    "alpha = .65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the expected click rate for each bid\n",
    "# if change the CDF also update dRdb in dLdb(bids,batch)\n",
    "def ExpectedClickRate(bids):\n",
    "    arr = np.zeros(36)\n",
    "    for i in range(36):\n",
    "        s = 0 \n",
    "        if bids[i]>10:\n",
    "            for j in range(5):\n",
    "                prob = (10/(10+lm[i]))*np.exp(-(bids[i]-10)/lm[i])\n",
    "                s += scipy.special.binom(4,j)*click_rates_by_rank[j]*(prob**j)*((1-prob)**(4-j))\n",
    "        else:\n",
    "            for j in range(5):\n",
    "                prob = 1 - (bids[i]/10)*lm[i]/(10+lm[i])\n",
    "                s += scipy.special.binom(4,j)*click_rates_by_rank[j]*(prob**j)*((1-prob)**(4-j))\n",
    "        arr[i]=s\n",
    "    return arr\n",
    "\n",
    "def ExpectedCost(bids,batch):\n",
    "    clicks = ExpectedClickRate(bids)\n",
    "    s = 0\n",
    "    for a in batch:\n",
    "        # add up bid for each customer times probability to click\n",
    "        s+= bids[a]*clicks[a]\n",
    "    return s\n",
    "\n",
    "        \n",
    "def ExpectedPoliciesSold(bids,batch):\n",
    "    clicks = ExpectedClickRate(bids)\n",
    "    s = 0\n",
    "    for a in batch:\n",
    "        # add up probability to click times probability to buy conditioned on click\n",
    "        s+= p[a]*clicks[a]\n",
    "    return s\n",
    "    \n",
    "# Loss here is log(cost per customer acquired) with constraint to ensure minimum is greater than 400. \n",
    "# Seek to minimize loss function\n",
    "def Loss(bids,batch):\n",
    "    policies = ExpectedPoliciesSold(bids,batch)\n",
    "    return np.log( ExpectedCost(bids,batch)) - np.log(policies) + alpha*np.log((policies-399)/(policies-400))\n",
    "\n",
    "# calculate the gradient of Loss function\n",
    "# to change CDF need to chance dRdb\n",
    "def dLdb(bids,batch):\n",
    "    clicks = ExpectedClickRate(bids)\n",
    "    cost = ExpectedCost(bids,batch)\n",
    "    policies = ExpectedPoliciesSold(bids,batch)\n",
    "    \n",
    "    # compute gradient of ExpectedClickRate\n",
    "    dRdb = np.zeros(36)\n",
    "    # compute gradient of ExpectedCost\n",
    "    dCdb = np.zeros(36)\n",
    "    # compute gradient of ExpectedPoliciesSold\n",
    "    dPdb = np.zeros(36)\n",
    "    for i in range(36):\n",
    "        s=0\n",
    "        if bids[i]>10:\n",
    "            prob = (10/(10+lm[i]))*np.exp(-(bids[i]-10)/lm[i])\n",
    "            dpdb = -(10/(10+lm[i]))*np.exp(-(bids[i]-10)/lm[i])/lm[i]\n",
    "        else:\n",
    "            prob = 1 - lm[i]*(bids[i]/10)/(10+lm[i])\n",
    "            dpdb = -(lm[i]/10)/(10+lm[i])\n",
    "        for j in range(5):\n",
    "            s += scipy.special.binom(4,j)*click_rates_by_rank[j]*j*(prob**(j-1))*((1-prob)**(4-j))*dpdb\n",
    "            s -= scipy.special.binom(4,j)*click_rates_by_rank[j]*(prob**j)*((1-prob)**(3-j))*(4-j)*dpdb\n",
    "        \n",
    "        # set value of gradient Expected click rate\n",
    "        dRdb[i] = s\n",
    "        \n",
    "        dCdb[i] += clicks[i]\n",
    "        dCdb[i] += bids[i]*dRdb[i]\n",
    "        \n",
    "        dPdb[i] += p[i]*dRdb[i]\n",
    "        \n",
    "    # now compute the gradient of Loss\n",
    "    arr = np.zeros(36)\n",
    "    for a in batch:\n",
    "        arr[a] += dCdb[a]/cost - dPdb[a]/policies + alpha*dPdb[a]*( 1/(policies - 399) - 1/(policies-400))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations Performed: 29669\n",
      "Final bids =  [ 4.83675569  4.51914476  5.3784541   5.41659753  3.56590062  3.60177059\n",
      "  4.58636127  4.59731314  3.34201539  3.33424812  4.33382715  4.3134977\n",
      "  6.44756991  6.59616941  7.03910891  6.989196    5.69546412  5.65828293\n",
      "  6.06794371  6.14040513  4.92498097  5.07040853  5.87557452 10.\n",
      "  7.67089213  7.51739714  7.61212137  7.58314208  6.20033719  6.13577726\n",
      "  6.84183362  6.9756924   5.80164398  5.7736762   7.1214125   7.11152196]\n",
      "Cost  6453.04413896888\n",
      "Policies  416.6756919014682\n",
      "Cost per policy  15.486970477017506\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize all bids at $10\n",
    "b=10*np.ones(36)\n",
    "\n",
    "# Number of iterations to do grad descent\n",
    "niterations=int(3*1e4)\n",
    "\n",
    "\n",
    "# Learning rate\n",
    "epsilon=.1\n",
    "\n",
    "m=10000\n",
    "# minimum possible bid\n",
    "min_val = 0.01\n",
    "\n",
    "samples = df[\"class\"].to_numpy()\n",
    "batch = samples #np.random.choice(samples, size=m, replace=True)\n",
    "\n",
    "losses=np.zeros(niterations+1)\n",
    "losses[0]=Loss(b, batch)\n",
    "for i in range(niterations):\n",
    "    # batch = np.random.choice(samples, size=m, replace=True)\n",
    "    grad = dLdb(b, batch)\n",
    "    if sum(np.abs(grad))<.01:\n",
    "        print(\"Number of Iterations Performed:\",i)\n",
    "        break\n",
    "    b = b-epsilon*grad\n",
    "    # set any negative values to min_val\n",
    "    b[b<min_val] = min_val\n",
    "    losses[i+1]=Loss(b,batch)\n",
    "    if ExpectedPoliciesSold(b,batch)<400:\n",
    "        break\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses[losses>0])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"iteration number\")\n",
    "#plt.yscale(\"log\")\n",
    "print(\"Final bids = \",b)\n",
    "print(\"Cost \", ExpectedCost(b,samples))\n",
    "print(\"Policies \", ExpectedPoliciesSold(b,samples))\n",
    "print(\"Cost per policy \", ExpectedCost(b,samples)/ExpectedPoliciesSold(b,samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Estimate of the Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have optimized the cost per policy sold subject to the constraint that we sell at least 400 policies per 10,000, on average, we want to estimate a confidence percentage that our bid strategy will actually acquire at least 400 customers out of 10,000. \n",
    "\n",
    "To do this we use bootstrapping to repeatedly produce samples of 10,000 customers from the emperical distribution and use this to estimate the standard deviation of policies per 10,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  416.6822107189277\n",
      "St Dev:  2.277501185107887\n"
     ]
    }
   ],
   "source": [
    "niterations=10000\n",
    "arr= np.zeros(niterations)\n",
    "for i in range(niterations):\n",
    "    batch = np.random.choice(samples, size=10000, replace=True)\n",
    "    arr[i] = ExpectedPoliciesSold(b, batch)\n",
    "m = np.mean(arr)\n",
    "s = np.std(arr)\n",
    "print(\"Mean: \", m)\n",
    "print(\"St Dev: \",s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude with high degree of confidence that the true number of customers will be greater than 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1963936642218857e-13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.cdf(400, loc=m,scale=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one customer class that has no representatives. We set this bid value to NaN\n",
    "b[b==10] = np.NaN\n",
    "ls[\"bid\"] = b\n",
    "ls[\"p\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insured</th>\n",
       "      <th>cars</th>\n",
       "      <th>drivers</th>\n",
       "      <th>married</th>\n",
       "      <th>bid</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>7.670892</td>\n",
       "      <td>0.467218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>7.612121</td>\n",
       "      <td>0.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>7.583142</td>\n",
       "      <td>0.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.517397</td>\n",
       "      <td>0.467218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>7.121412</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>7.111522</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>7.039109</td>\n",
       "      <td>0.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>6.989196</td>\n",
       "      <td>0.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>6.975692</td>\n",
       "      <td>0.432213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>6.841834</td>\n",
       "      <td>0.432213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>6.596169</td>\n",
       "      <td>0.467218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>6.447570</td>\n",
       "      <td>0.467218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>6.200337</td>\n",
       "      <td>0.370780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>6.140405</td>\n",
       "      <td>0.432213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>6.135777</td>\n",
       "      <td>0.370780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>6.067944</td>\n",
       "      <td>0.432213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>5.875575</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>5.801644</td>\n",
       "      <td>0.355041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>5.773676</td>\n",
       "      <td>0.355041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>5.695464</td>\n",
       "      <td>0.370780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>5.658283</td>\n",
       "      <td>0.370780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>5.416598</td>\n",
       "      <td>0.386995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>5.378454</td>\n",
       "      <td>0.386995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>5.070409</td>\n",
       "      <td>0.355041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>4.924981</td>\n",
       "      <td>0.355041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>4.836756</td>\n",
       "      <td>0.328273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>4.597313</td>\n",
       "      <td>0.297859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>4.586361</td>\n",
       "      <td>0.297859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>4.519145</td>\n",
       "      <td>0.328273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>4.333827</td>\n",
       "      <td>0.283818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>4.313498</td>\n",
       "      <td>0.283818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>3.601771</td>\n",
       "      <td>0.247208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>3.565901</td>\n",
       "      <td>0.247208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>3.342015</td>\n",
       "      <td>0.234757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>3.334248</td>\n",
       "      <td>0.234757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    insured cars drivers married       bid         p\n",
       "24        N    1       1       M  7.670892  0.467218\n",
       "26        N    1       2       M  7.612121  0.531141\n",
       "27        N    1       2       S  7.583142  0.531141\n",
       "25        N    1       1       S  7.517397  0.467218\n",
       "34        N    3       2       M  7.121412  0.415588\n",
       "35        N    3       2       S  7.111522  0.415588\n",
       "14  unknown    1       2       M  7.039109  0.531141\n",
       "15  unknown    1       2       S  6.989196  0.531141\n",
       "31        N    2       2       S  6.975692  0.432213\n",
       "30        N    2       2       M  6.841834  0.432213\n",
       "13  unknown    1       1       S  6.596169  0.467218\n",
       "12  unknown    1       1       M  6.447570  0.467218\n",
       "28        N    2       1       M  6.200337  0.370780\n",
       "19  unknown    2       2       S  6.140405  0.432213\n",
       "29        N    2       1       S  6.135777  0.370780\n",
       "18  unknown    2       2       M  6.067944  0.432213\n",
       "22  unknown    3       2       M  5.875575  0.415588\n",
       "32        N    3       1       M  5.801644  0.355041\n",
       "33        N    3       1       S  5.773676  0.355041\n",
       "16  unknown    2       1       M  5.695464  0.370780\n",
       "17  unknown    2       1       S  5.658283  0.370780\n",
       "3         Y    1       2       S  5.416598  0.386995\n",
       "2         Y    1       2       M  5.378454  0.386995\n",
       "21  unknown    3       1       S  5.070409  0.355041\n",
       "20  unknown    3       1       M  4.924981  0.355041\n",
       "0         Y    1       1       M  4.836756  0.328273\n",
       "7         Y    2       2       S  4.597313  0.297859\n",
       "6         Y    2       2       M  4.586361  0.297859\n",
       "1         Y    1       1       S  4.519145  0.328273\n",
       "10        Y    3       2       M  4.333827  0.283818\n",
       "11        Y    3       2       S  4.313498  0.283818\n",
       "5         Y    2       1       S  3.601771  0.247208\n",
       "4         Y    2       1       M  3.565901  0.247208\n",
       "8         Y    3       1       M  3.342015  0.234757\n",
       "9         Y    3       1       S  3.334248  0.234757\n",
       "23  unknown    3       2       S       NaN  0.415588"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.sort_values(\"bid\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
